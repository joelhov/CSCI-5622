# -*- coding: utf-8 -*-
"""
Created on Thu Dec 12 15:32:55 2024

@author: joelh
"""
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix


df = pd.read_csv('C:/Users/joelh/OneDrive/Desktop/CSCI5622/Proj/DT.csv')
df.head()

values = {'Critic_Score': 0, 'Critic_Count': 0, 'User_Score': 0, 'User_Count': 0}
df['Critic_Score'].fillna(0, inplace=True)
df['Critic_Count'].fillna(0, inplace=True)
df['User_Score'].fillna(0, inplace=True)
df['User_Count'].fillna(0, inplace=True)
df.loc[df['Publisher']=='Nintendo', ['Developer']] = 'Nintendo'
df.loc[df['Publisher']=='Nintendo', ['Rating']] = 'E'
df.loc[df['Publisher']=='Activision', ['Rating']] = 'M'
df.loc[df['Publisher']=='Activision', ['Developer']] = 'Treyarch'
df.loc[df['User_Score']=='tbd', ['User_Score']] = 0
df['User_Score']=df['User_Score'].astype(np.number)

del df['Year_of_Release']
df = df.dropna(how='any',axis=0)
pd.isnull(df).sum() > 0

ratingsEM = df.copy()
del ratingsEM['NA_Sales']
del ratingsEM['EU_Sales']
del ratingsEM['JP_Sales']
del ratingsEM['Other_Sales']
ratingsEM.head()


def create_label_encoder_dict(df):
    from sklearn.preprocessing import LabelEncoder

    label_encoder_dict = {}
    for column in df.columns:
        # Only create encoder for categorical data types
        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':
            label_encoder_dict[column]= LabelEncoder().fit(df[column].astype(str))
    return label_encoder_dict

label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

ratingsEM_data = ratingsEM.copy() # create copy of initial data set
for column in ratingsEM_data.columns:
    if column in label_encoders:
        ratingsEM_data[column] = label_encoders[column].transform(ratingsEM_data[column])
print("Transformed data set")
print("="*32)
ratingsEM_data.head()



X_data = ratingsEM_data[['Platform', 'Genre', 'Publisher', 'Developer']]
Y_data = ratingsEM_data['Rating']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

clf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)

clf.fit(X_train, y_train)

pd.DataFrame([ "%.2f%%" % perc for perc in (clf.feature_importances_ * 100)], \
             index = X_data.columns, columns = ['Feature Significance in Decision Tree'])



figureObject, axesObject = plt.subplots()
axesObject.pie(clf.feature_importances_ * 100, labels=X_data.columns,autopct='%1.2f',startangle=90)
axesObject.axis('equal')
plt.title('Feature Significance in Decision Tree')


def tree_to_code(tree, feature_names, label_encoders={}):
    from sklearn.tree import _tree
    '''
     Outputs a decision tree model as a Python function
     Parameters:
     -----------
     tree: decision tree model
     The decision tree to represent as a function
     feature_names: list
     The feature names of the dataset used for building the decision tree
     '''
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    print("def decision_tree({}):".format(", ".join(feature_names)))
    def recurse(node, depth):
        indent = " " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, threshold))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else: # if {} > {}".format(indent, name, threshold))
            recurse(tree_.children_right[node], depth + 1)
        else:
            #print(node)

            name = tree_.feature[node]
            if name in label_encoders:
                if isinstance(label_encoders[name] , LabelEncoder) or True:
                    print ("{}-return {}".format(indent, label_encoders[name].inverse_transform(tree_.value[node])))
                    return
            print("{}return {} # Distribution of samples in node".format(indent, tree_.value[node]))
    recurse(0, 1)


label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

k=(clf.predict(X_test) == y_test) 
k.value_counts()
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test, clf.predict(X_test), labels=y_test.unique())
cm

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import OrdinalEncoder

lab = list(ratingsEM['Rating'].unique())
lab.pop()
lab


disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lab)
disp.plot()
disp.ax_.set_title("Decision Tree CM")
plt.show()

class_names=[0,1] 
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cm), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix for Decision Tree', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

lab = list(ratingsEM['Rating'].unique())
lab.pop()
lab



import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt


df = pd.read_csv('C:/Users/joelh/OneDrive/Desktop/CSCI5622/Proj/DT.csv')
df.head()

values = {'Critic_Score': 0, 'Critic_Count': 0, 'User_Score': 0, 'User_Count': 0}
df['Critic_Score'].fillna(0, inplace=True)
df['Critic_Count'].fillna(0, inplace=True)
df['User_Score'].fillna(0, inplace=True)
df['User_Count'].fillna(0, inplace=True)
df.loc[df['Publisher']=='Nintendo', ['Developer']] = 'Nintendo'
df.loc[df['Publisher']=='Nintendo', ['Rating']] = 'E'
df.loc[df['Publisher']=='Activision', ['Rating']] = 'M'
df.loc[df['Publisher']=='Activision', ['Developer']] = 'Treyarch'
df.loc[df['User_Score']=='tbd', ['User_Score']] = 0
df['User_Score']=df['User_Score'].astype(np.number)

del df['Year_of_Release']
df = df.dropna(how='any',axis=0)
pd.isnull(df).sum() > 0

ratingsEM = df.copy()
del ratingsEM['NA_Sales']
del ratingsEM['EU_Sales']
del ratingsEM['JP_Sales']
del ratingsEM['Other_Sales']
ratingsEM.head()


def create_label_encoder_dict(df):
    from sklearn.preprocessing import LabelEncoder

    label_encoder_dict = {}
    for column in df.columns:
        # Only create encoder for categorical data types
        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':
            label_encoder_dict[column]= LabelEncoder().fit(df[column].astype(str))
    return label_encoder_dict

label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

ratingsEM_data = ratingsEM.copy() # create copy of initial data set
for column in ratingsEM_data.columns:
    if column in label_encoders:
        ratingsEM_data[column] = label_encoders[column].transform(ratingsEM_data[column])
print("Transformed data set")
print("="*32)
ratingsEM_data.head()



X_data = ratingsEM_data[['Platform', 'Genre', 'Publisher', 'Developer']]
Y_data = ratingsEM_data['Rating']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

clf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)

clf.fit(X_train, y_train)

pd.DataFrame([ "%.2f%%" % perc for perc in (clf.feature_importances_ * 100)], \
             index = X_data.columns, columns = ['Feature Significance in Decision Tree'])



figureObject, axesObject = plt.subplots()
axesObject.pie(clf.feature_importances_ * 100, labels=X_data.columns,autopct='%1.2f',startangle=90)
axesObject.axis('equal')
plt.title('Feature Significance in Decision Tree')


dot_data = tree.export_graphviz(clf,out_file=None,
feature_names=X_data.columns,
class_names=label_encoders[Y_data.name].classes_,
filled=True, rounded=True, proportion=True,
node_ids=True, #impurity=False,
special_characters=True)
graph = graphviz.Source(dot_data)
graph

def tree_to_code(tree, feature_names, label_encoders={}):
    from sklearn.tree import _tree
    '''
     Outputs a decision tree model as a Python function
     Parameters:
     -----------
     tree: decision tree model
     The decision tree to represent as a function
     feature_names: list
     The feature names of the dataset used for building the decision tree
     '''
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    print("def decision_tree({}):".format(", ".join(feature_names)))
    def recurse(node, depth):
        indent = " " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, threshold))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else: # if {} > {}".format(indent, name, threshold))
            recurse(tree_.children_right[node], depth + 1)
        else:
            #print(node)

            name = tree_.feature[node]
            if name in label_encoders:
                if isinstance(label_encoders[name] , LabelEncoder) or True:
                    print ("{}-return {}".format(indent, label_encoders[name].inverse_transform(tree_.value[node])))
                    return
            print("{}return {} # Distribution of samples in node".format(indent, tree_.value[node]))
    recurse(0, 1)


label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

k=(clf.predict(X_test) == y_test) 
k.value_counts()
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test, clf.predict(X_test), labels=y_test.unique())
cm

from sklearn.metrics import classification_report

print(classification_report(y_test, clf.predict(X_test)))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import OrdinalEncoder

lab = list(ratingsEM['Rating'].unique())
lab.pop()
lab


disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lab)
disp.plot()
disp.ax_.set_title("Decision Tree CM")
plt.show()

class_names=[0,1] 
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cm), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix for Decision Tree', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

lab = list(ratingsEM['Rating'].unique())
lab.pop()
lab

#tree.plot_tree(clf)


# -*- coding: utf-8 -*-
"""
Created on Thu Dec 12 15:32:55 2024

@author: joelh
"""
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt


df = pd.read_csv('C:/Users/joelh/OneDrive/Desktop/CSCI5622/Proj/DT.csv')
df.head()

values = {'Critic_Score': 0, 'Critic_Count': 0, 'User_Score': 0, 'User_Count': 0}
df['Critic_Score'].fillna(0, inplace=True)
df['Critic_Count'].fillna(0, inplace=True)
df['User_Score'].fillna(0, inplace=True)
df['User_Count'].fillna(0, inplace=True)
df.loc[df['Publisher']=='Nintendo', ['Developer']] = 'Nintendo'
df.loc[df['Publisher']=='Nintendo', ['Rating']] = 'E'
df.loc[df['Publisher']=='Activision', ['Rating']] = 'M'
df.loc[df['Publisher']=='Activision', ['Developer']] = 'Treyarch'
df.loc[df['User_Score']=='tbd', ['User_Score']] = 0
df['User_Score']=df['User_Score'].astype(np.number)

del df['Year_of_Release']
df = df.dropna(how='any',axis=0)
pd.isnull(df).sum() > 0

ratingsEM = df.copy()
del ratingsEM['NA_Sales']
del ratingsEM['EU_Sales']
del ratingsEM['JP_Sales']
del ratingsEM['Other_Sales']
ratingsEM.head()


def create_label_encoder_dict(df):
    from sklearn.preprocessing import LabelEncoder

    label_encoder_dict = {}
    for column in df.columns:
        # Only create encoder for categorical data types
        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':
            label_encoder_dict[column]= LabelEncoder().fit(df[column].astype(str))
    return label_encoder_dict

label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

ratingsEM_data = ratingsEM.copy() # create copy of initial data set
for column in ratingsEM_data.columns:
    if column in label_encoders:
        ratingsEM_data[column] = label_encoders[column].transform(ratingsEM_data[column])
print("Transformed data set")
print("="*32)
ratingsEM_data.head()



X_data = ratingsEM_data[['Rating', 'Genre', 'Publisher', 'Developer']]
Y_data = ratingsEM_data['Platform']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

clf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)

clf.fit(X_train, y_train)

pd.DataFrame([ "%.2f%%" % perc for perc in (clf.feature_importances_ * 100)], \
             index = X_data.columns, columns = ['Feature Significance in Decision Tree'])



figureObject, axesObject = plt.subplots()
axesObject.pie(clf.feature_importances_ * 100, labels=X_data.columns,autopct='%1.2f',startangle=90)
axesObject.axis('equal')
plt.title('Feature Significance in Decision Tree')



def tree_to_code(tree, feature_names, label_encoders={}):
    from sklearn.tree import _tree
    '''
     Outputs a decision tree model as a Python function
     Parameters:
     -----------
     tree: decision tree model
     The decision tree to represent as a function
     feature_names: list
     The feature names of the dataset used for building the decision tree
     '''
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    print("def decision_tree({}):".format(", ".join(feature_names)))
    def recurse(node, depth):
        indent = " " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, threshold))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else: # if {} > {}".format(indent, name, threshold))
            recurse(tree_.children_right[node], depth + 1)
        else:
            #print(node)

            name = tree_.feature[node]
            if name in label_encoders:
                if isinstance(label_encoders[name] , LabelEncoder) or True:
                    print ("{}-return {}".format(indent, label_encoders[name].inverse_transform(tree_.value[node])))
                    return
            print("{}return {} # Distribution of samples in node".format(indent, tree_.value[node]))
    recurse(0, 1)


label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

k=(clf.predict(X_test) == y_test) 
k.value_counts()
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test, clf.predict(X_test), labels=y_test.unique())
cm
sum(cm)
sum([426, 536,  24, 161,  64, 315, 410, 220,   8, 342, 125,  79, 250,48, 103,  15,   6,   0,   0,  25,   3,   4])

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import OrdinalEncoder

lab = list(ratingsEM['Platform'].unique())


disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lab)
disp.plot()
disp.ax_.set_title("Decision Tree CM")
plt.show()

class_names=[0,1] 
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cm), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix for Decision Tree', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')






#tree.plot_tree(clf)








import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt


df = pd.read_csv('C:/Users/joelh/OneDrive/Desktop/CSCI5622/Proj/DT.csv')
df.head()

values = {'Critic_Score': 0, 'Critic_Count': 0, 'User_Score': 0, 'User_Count': 0}
df['Critic_Score'].fillna(0, inplace=True)
df['Critic_Count'].fillna(0, inplace=True)
df['User_Score'].fillna(0, inplace=True)
df['User_Count'].fillna(0, inplace=True)
df.loc[df['Publisher']=='Nintendo', ['Developer']] = 'Nintendo'
df.loc[df['Publisher']=='Nintendo', ['Rating']] = 'E'
df.loc[df['Publisher']=='Activision', ['Rating']] = 'M'
df.loc[df['Publisher']=='Activision', ['Developer']] = 'Treyarch'
df.loc[df['User_Score']=='tbd', ['User_Score']] = 0
df['User_Score']=df['User_Score'].astype(np.number)

del df['Year_of_Release']
df = df.dropna(how='any',axis=0)
pd.isnull(df).sum() > 0

ratingsEM = df.copy()
del ratingsEM['NA_Sales']
del ratingsEM['EU_Sales']
del ratingsEM['JP_Sales']
del ratingsEM['Other_Sales']
ratingsEM.head()


def create_label_encoder_dict(df):
    from sklearn.preprocessing import LabelEncoder

    label_encoder_dict = {}
    for column in df.columns:
        # Only create encoder for categorical data types
        if not np.issubdtype(df[column].dtype, np.number) and column != 'Age':
            label_encoder_dict[column]= LabelEncoder().fit(df[column].astype(str))
    return label_encoder_dict

label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

ratingsEM_data = ratingsEM.copy() # create copy of initial data set
for column in ratingsEM_data.columns:
    if column in label_encoders:
        ratingsEM_data[column] = label_encoders[column].transform(ratingsEM_data[column])
print("Transformed data set")
print("="*32)
ratingsEM_data.head()



X_data = ratingsEM_data[['Platform', 'Rating', 'Publisher', 'Developer']]
Y_data = ratingsEM_data['Genre']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

clf = DecisionTreeClassifier(criterion='entropy',min_samples_split=2)

clf.fit(X_train, y_train)

pd.DataFrame([ "%.2f%%" % perc for perc in (clf.feature_importances_ * 100)], \
             index = X_data.columns, columns = ['Feature Significance in Decision Tree'])



figureObject, axesObject = plt.subplots()
axesObject.pie(clf.feature_importances_ * 100, labels=X_data.columns,autopct='%1.2f',startangle=90)
axesObject.axis('equal')
plt.title('Feature Significance in Decision Tree')



def tree_to_code(tree, feature_names, label_encoders={}):
    from sklearn.tree import _tree
    '''
     Outputs a decision tree model as a Python function
     Parameters:
     -----------
     tree: decision tree model
     The decision tree to represent as a function
     feature_names: list
     The feature names of the dataset used for building the decision tree
     '''
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]
    print("def decision_tree({}):".format(", ".join(feature_names)))
    def recurse(node, depth):
        indent = " " * depth
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            print("{}if {} <= {}:".format(indent, name, threshold))
            recurse(tree_.children_left[node], depth + 1)
            print("{}else: # if {} > {}".format(indent, name, threshold))
            recurse(tree_.children_right[node], depth + 1)
        else:
            #print(node)

            name = tree_.feature[node]
            if name in label_encoders:
                if isinstance(label_encoders[name] , LabelEncoder) or True:
                    print ("{}-return {}".format(indent, label_encoders[name].inverse_transform(tree_.value[node])))
                    return
            print("{}return {} # Distribution of samples in node".format(indent, tree_.value[node]))
    recurse(0, 1)


label_encoders = create_label_encoder_dict(ratingsEM)
print("Encoded Values for each Label")
print("="*32)
for column in label_encoders:
    print("="*32)
    print('Encoder(%s) = %s' % (column, label_encoders[column].classes_ ))
    print(pd.DataFrame([range(0,len(label_encoders[column].classes_))], columns=label_encoders[column].classes_, index=['Encoded Values'] ).T)

k=(clf.predict(X_test) == y_test) 
k.value_counts()
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test, clf.predict(X_test), labels=y_test.unique())
cm
sum([831, 250, 545, 228,  95, 225, 291, 204, 144,  83, 119, 149])


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics

from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import OrdinalEncoder

lab = list(ratingsEM['Genre'].unique())


disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lab)
disp.plot()
disp.ax_.set_title("Decision Tree CM")
plt.show()

class_names=[0,1] 
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

sns.heatmap(pd.DataFrame(cm), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix for Decision Tree', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')


#tree.plot_tree(clf)










"Followed along with the Video Games Sales WIth Ratings Decision Tree by Lemar https://www.kaggle.com/code/lemargray/video-games-sales-with-ratings-decision-tree"

















"Followed along with the Video Games Sales WIth Ratings Decision Tree by Lemar https://www.kaggle.com/code/lemargray/video-games-sales-with-ratings-decision-tree"








